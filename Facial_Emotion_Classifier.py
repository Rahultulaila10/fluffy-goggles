# -*- coding: utf-8 -*-
"""BVC_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1quNBHiJFNTGcPjGNIO52Pfp_GcSjUZjW
"""

import numpy as np
import pandas as pd # data processing
from tensorflow import keras
from keras.layers.convolutional import Conv2D, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization
from keras.layers import Dense, Dropout, Activation, Flatten
from keras import Sequential

data = pd.read_csv('fer2013.csv')
print(data)
print(data['Usage'].value_counts())

#splitting the data into three parts
training_data = data[data['Usage']=='Training']
testing_data = data[data['Usage']=='PublicTest']
validation_data = data[data['Usage']=='PrivateTest']

#preprocessing the data
def preprocessing(df):
    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])
    data_X = np.array(df['pixels'].tolist(), dtype='float32').reshape(-1, 48, 48, 1) / 255.0
    data_Y = keras.utils.to_categorical(df['emotion'], 7)
    return data_X, data_Y


train_X, train_Y = preprocessing(training_data)  # training data
validation_X, validation_Y = preprocessing(validation_data)  # validation data
test_X, test_Y = preprocessing(testing_data)  # test data

#Creating a CNN Model
model=Sequential()

model.add(Conv2D(64,kernel_size=(3,3),input_shape=(48,48,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(64,kernel_size=(3,3),input_shape=(48,48,1),padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))

model.add(Conv2D(128,kernel_size=(3,3),input_shape=(48,48,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(128,kernel_size=(3,3),input_shape=(48,48,1),padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))

model.add(Conv2D(128,kernel_size=(3,3),input_shape=(48,48,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(128,kernel_size=(3,3),input_shape=(48,48,1),padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(128,kernel_size=(3,3),input_shape=(48,48,1),padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))

model.add(Conv2D(512,kernel_size=(3,3),input_shape=(48,48,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(512,kernel_size=(3,3),input_shape=(48,48,1),padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(512,kernel_size=(3,3),input_shape=(48,48,1),padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))

model.add(Flatten())

model.add(Dense(64))
#model.add(Dropout(0.3))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Dense(64))
#model.add(Dropout(0.3))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Dense(7,activation='softmax'))
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
print(model.summary())
model.fit(train_X,train_Y,validation_data=(validation_X,validation_Y),epochs=10,batch_size=32)

model.evaluate(test_X,test_Y,verbose=0)
#print("Loss:",evaluation[0])
#print("Accuracy:",evaluation[1])
prediction=model.predict(test_X)
prediction_labels=[np.argmax(i) for i in prediction]
print(prediction_labels[:20])
test_y_new=[np.argmax(i) for i in test_Y]
print(test_y_new[:20])

from sklearn.metrics import confusion_matrix
import itertools
import matplotlib.pyplot as plt
cm=confusion_matrix(y_true=test_y_new,y_pred=prediction_labels)

def plot_confusion_matrix(cm, classes,
                        normalize=False,
                        title='Confusion matrix',
                        cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

cm_plot_labels=['Angry','Disgust','Fear','Happy','Sadness','Surprise','Neutral']
plot_confusion_matrix(cm=cm,classes=cm_plot_labels,title='Confusion Matrix')

from sklearn.metrics import classification_report
print(classification_report(test_y_new,prediction_labels))
from sklearn.metrics import accuracy_score